{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from constants import CLASSIFIERS_FOLDER\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors.classification import RadiusNeighborsClassifier\n",
    "from sklearn.neighbors.classification import KNeighborsClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "from sklearn.linear_model.ridge import RidgeClassifierCV\n",
    "from sklearn.linear_model.ridge import RidgeClassifier\n",
    "from sklearn.linear_model.passive_aggressive import PassiveAggressiveClassifier\n",
    "from sklearn.gaussian_process.gpc import GaussianProcessClassifier\n",
    "#from sklearn.ensemble.voting_classifier import VotingClassifier\n",
    "from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.ensemble.bagging import BaggingClassifier\n",
    "from sklearn.ensemble.forest import ExtraTreesClassifier\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm.classes import OneClassSVM\n",
    "#from sklearn.mixture import DPGMM\n",
    "#from sklearn.mixture import GMM\n",
    "from sklearn.mixture import GaussianMixture\n",
    "#from sklearn.mixture import VBGMM\n",
    "\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.load('X.npy')\n",
    "# X = np.load('X_left.npy')\n",
    "X = np.load('X_right.npy')\n",
    "y = np.load('y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Test Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve(model, X_train, X_test, y_train, y_test):\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for i in np.arange(0.1, 1.1, 0.1):\n",
    "        train_size = int(len(X_train) * i)\n",
    "        X_train_ = X_train[:train_size]\n",
    "        y_train_ = y_train[:train_size]\n",
    "        \n",
    "        model_ = clone(model)\n",
    "        model_.fit(X_train_, y_train_)\n",
    "        train_pred = model_.predict(X_train_)\n",
    "        test_pred = model_.predict(X_test)\n",
    "        \n",
    "        train_acc = accuracy_score(y_train_, train_pred)\n",
    "        test_acc = accuracy_score(y_test, test_pred)\n",
    "        \n",
    "        train_scores.append(train_acc)\n",
    "        test_scores.append(test_acc)\n",
    "        \n",
    "        print(f'{int(i * 100)}%', end=' ')\n",
    "    print()\n",
    "        \n",
    "    plt.plot(train_scores, label='Train')\n",
    "    plt.plot(test_scores, label='Test')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('% of Training Size')\n",
    "    plt.xticks(range(10), (np.arange(0.1, 1.1, 0.1) * 100).astype(int))\n",
    "    plt.ylim(0.0, 1.01)\n",
    "    plt.legend()\n",
    "    \n",
    "    print(f'Final Training Accuracy: {train_scores[-1] * 100}%')\n",
    "    print(f'Final Testing Accuracy: {test_scores[-1] * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    ExtraTreeClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    MLPClassifier(),\n",
    "    NearestCentroid(),\n",
    "    #RadiusNeighborsClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    #ClassifierChain(),\n",
    "    #MultiOutputClassifier(),\n",
    "    #OutputCodeClassifier(),\n",
    "    #OneVsOneClassifier(),\n",
    "    #OneVsRestClassifier(),\n",
    "    SGDClassifier(),\n",
    "    RidgeClassifierCV(),\n",
    "    RidgeClassifier(),\n",
    "    PassiveAggressiveClassifier(),\n",
    "    ##GaussianProcessClassifier(),\n",
    "#     VotingClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    BaggingClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    CalibratedClassifierCV(),\n",
    "    BernoulliNB(),\n",
    "    GaussianNB(),\n",
    "    LabelPropagation(),\n",
    "    LabelSpreading(),\n",
    "    LogisticRegression(),\n",
    "    LogisticRegressionCV(),\n",
    "    Perceptron(),\n",
    "    #MultinomialNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    SVC(),\n",
    "    LinearSVC(),\n",
    "    #NuSVC(),\n",
    "    ##OneClassSVM(),\n",
    "#     DPGMM(),\n",
    "#     GMM(),\n",
    "    GaussianMixture(),\n",
    "#     VBGMM()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreeClassifier etc-t-t 0.9540833060019679 0.7433628318584071\n",
      "DecisionTreeClassifier dtc-t-t 0.9540833060019679 0.8023598820058997\n",
      "MLPClassifier mlpc-n-m 0.8934076746474254 0.8495575221238938\n",
      "NearestCentroid nc-n-n 0.3876680878976714 0.4277286135693215\n",
      "KNeighborsClassifier knc-n-c 0.8838963594621188 0.8584070796460177\n",
      "SGDClassifier sgdc-l-s 0.670055755985569 0.6843657817109144\n",
      "RidgeClassifierCV rccv-l-r 0.722859954083306 0.6902654867256637\n",
      "RidgeClassifier rc-l-r 0.722859954083306 0.6902654867256637\n",
      "PassiveAggressiveClassifier pac-l-p 0.5080354214496556 0.5250737463126843\n",
      "AdaBoostClassifier abc-e-w 0.23122335191866186 0.23008849557522124\n",
      "GradientBoostingClassifier gbc-e-g 0.9540833060019679 0.8377581120943953\n",
      "BaggingClassifier bc-e-b 0.9508035421449655 0.8495575221238938\n",
      "ExtraTreesClassifier etc-e-f 0.9540833060019679 0.8613569321533924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanhw\\Miniconda3\\envs\\p2-unsigned-cpu\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\yanhw\\Miniconda3\\envs\\p2-unsigned-cpu\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier rfc-e-f 0.9530993768448671 0.8584070796460177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanhw\\Miniconda3\\envs\\p2-unsigned-cpu\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalibratedClassifierCV cccv-c 0.7520498524106264 0.7345132743362832\n",
      "BernoulliNB bnb-n 0.26697277795998686 0.2920353982300885\n",
      "GaussianNB gnb-n 0.558543784847491 0.5899705014749262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanhw\\Miniconda3\\envs\\p2-unsigned-cpu\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelPropagation lp-s-l 0.9540833060019679 0.15634218289085547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanhw\\Miniconda3\\envs\\p2-unsigned-cpu\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\yanhw\\Miniconda3\\envs\\p2-unsigned-cpu\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\yanhw\\Miniconda3\\envs\\p2-unsigned-cpu\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelSpreading ls-s-l 0.9540833060019679 0.15634218289085547\n",
      "LogisticRegression lr-l-l 0.8740570678911118 0.8289085545722714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanhw\\Miniconda3\\envs\\p2-unsigned-cpu\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\yanhw\\Miniconda3\\envs\\p2-unsigned-cpu\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionCV lrcv-l-l 0.8478189570350935 0.8377581120943953\n",
      "Perceptron p-l-p 0.6589045588717612 0.6548672566371682\n",
      "QuadraticDiscriminantAnalysis qda-d 0.9176779271892423 0.6696165191740413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanhw\\Miniconda3\\envs\\p2-unsigned-cpu\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\yanhw\\Miniconda3\\envs\\p2-unsigned-cpu\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\yanhw\\Miniconda3\\envs\\p2-unsigned-cpu\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis lda-d 0.8461790751065923 0.8141592920353983\n",
      "SVC svc-s-c 0.9540833060019679 0.18584070796460178\n",
      "LinearSVC lsvc-s-c 0.625778943916038 0.6135693215339233\n",
      "GaussianMixture gm-m-g 0.14266972777959988 0.12389380530973451\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for classifier in classifiers:\n",
    "    name2 = str(type(classifier))[16:-2].split('.')\n",
    "    name2 = ''.join([c for c in name2[-1] if c.isupper()]).lower() + '-' + '-'.join(x[0] for x in name2[:-1])\n",
    "    name = type(classifier).__name__ + ' '+ name2\n",
    "    ignore_warnings(category=ConvergenceWarning)(classifier.fit)(X_train, y_train)\n",
    "    train_pred = classifier.predict(X_train)\n",
    "    test_pred = classifier.predict(X_test)\n",
    "    train_acc = accuracy_score(y_train, train_pred)\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "    scores.append((name, train_acc, test_acc))\n",
    "    print(name, train_acc, test_acc)\n",
    "    #learning_curve(classifer, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ExtraTreesClassifier etc-e-f 0.9540833060019679 0.8613569321533924\n",
      "1 KNeighborsClassifier knc-n-c 0.8838963594621188 0.8584070796460177\n",
      "2 RandomForestClassifier rfc-e-f 0.9530993768448671 0.8584070796460177\n",
      "3 MLPClassifier mlpc-n-m 0.8934076746474254 0.8495575221238938\n",
      "4 BaggingClassifier bc-e-b 0.9508035421449655 0.8495575221238938\n",
      "5 GradientBoostingClassifier gbc-e-g 0.9540833060019679 0.8377581120943953\n",
      "6 LogisticRegressionCV lrcv-l-l 0.8478189570350935 0.8377581120943953\n",
      "7 LogisticRegression lr-l-l 0.8740570678911118 0.8289085545722714\n",
      "8 LinearDiscriminantAnalysis lda-d 0.8461790751065923 0.8141592920353983\n",
      "9 DecisionTreeClassifier dtc-t-t 0.9540833060019679 0.8023598820058997\n",
      "10 ExtraTreeClassifier etc-t-t 0.9540833060019679 0.7433628318584071\n",
      "11 CalibratedClassifierCV cccv-c 0.7520498524106264 0.7345132743362832\n",
      "12 RidgeClassifierCV rccv-l-r 0.722859954083306 0.6902654867256637\n",
      "13 RidgeClassifier rc-l-r 0.722859954083306 0.6902654867256637\n",
      "14 SGDClassifier sgdc-l-s 0.670055755985569 0.6843657817109144\n",
      "15 QuadraticDiscriminantAnalysis qda-d 0.9176779271892423 0.6696165191740413\n",
      "16 Perceptron p-l-p 0.6589045588717612 0.6548672566371682\n",
      "17 LinearSVC lsvc-s-c 0.625778943916038 0.6135693215339233\n",
      "18 GaussianNB gnb-n 0.558543784847491 0.5899705014749262\n",
      "19 PassiveAggressiveClassifier pac-l-p 0.5080354214496556 0.5250737463126843\n",
      "20 NearestCentroid nc-n-n 0.3876680878976714 0.4277286135693215\n",
      "21 BernoulliNB bnb-n 0.26697277795998686 0.2920353982300885\n",
      "22 AdaBoostClassifier abc-e-w 0.23122335191866186 0.23008849557522124\n",
      "23 SVC svc-s-c 0.9540833060019679 0.18584070796460178\n",
      "24 LabelPropagation lp-s-l 0.9540833060019679 0.15634218289085547\n",
      "25 LabelSpreading ls-s-l 0.9540833060019679 0.15634218289085547\n",
      "26 GaussianMixture gm-m-g 0.14266972777959988 0.12389380530973451\n"
     ]
    }
   ],
   "source": [
    "scores.sort(key=lambda x: x[2], reverse=True)\n",
    "for i, score in enumerate(scores):\n",
    "    print(i, score[0], score[1], score[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str(type(NearestCentroid()))[16:-2].split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(CLASSIFIERS_FOLDER):\n",
    "    os.mkdir(CLASSIFIERS_FOLDER)\n",
    "    \n",
    "for classifier in classifiers:\n",
    "    name = str(type(classifier))[16:-2].split('.')\n",
    "    name = ''.join([c for c in name[-1] if c.isupper()]).lower() + '-' + '-'.join(x[0] for x in name[:-1])\n",
    "    with open(os.path.join(CLASSIFIERS_FOLDER, name), 'wb') as file:\n",
    "        pickle.dump(classifier, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2-unsigned-cpu",
   "language": "python",
   "name": "p2-unsigned-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
